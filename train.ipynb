{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "# model = YOLO(\"yolov8n.yaml\")  # build a new model from scratch\n",
    "model = YOLO('/home/personal/TaxtDetection/runs/detect/train15/weights/best.pt')  # load a .pt file\n",
    "\n",
    "# Use the model\n",
    "# model.train(data=\"config.yml\", epochs=50, resume=True)  # train the model\n",
    "# metrics = model.val()  # evaluate model performance on the validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/personal/TaxtDetection/venv/lib/python3.11/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11060). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "\n",
      "image 1/1 /home/personal/TaxtDetection/data/test/images/00047.jpg: 384x640 1 Tag, 67.7ms\n",
      "Speed: 4.3ms preprocess, 67.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from detect import Coords\n",
    "from PIL import Image\n",
    "imgPath = ('./test.jpg')\n",
    "# imgPath = ('./data/test/images/00047.jpg')\n",
    "\n",
    "results = model(imgPath)\n",
    "coords: list[Coords] = list()\n",
    "for result in results:\n",
    "    # print(result.boxes)\n",
    "    for box in result.boxes:\n",
    "        for xyxy in box.xyxy:\n",
    "            coord = Coords(xyxy[0], xyxy[1], xyxy[2], xyxy[3])\n",
    "            coords.append(coord)\n",
    "    # im_array = result.plot()  # plot a BGR numpy array of predictions\n",
    "    # im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
    "    # # im.show()  # show image\n",
    "    # im.save('results.jpg') \n",
    "# print(result[\"boxes\"])\n",
    "# import cv2\n",
    "# print(metrics)\n",
    "# path = model.export(format=\"onnx\") # export the model to ONNX format\n",
    "# print(path)\n",
    "# results = model(img)  # predict on an image\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coord in coords:\n",
    "    coord.drawBoundingBox(imgPath, saveImagePath='draw.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coord in coords:\n",
    "    # Crop image \n",
    "    coord.cropImage(imgPath, saveImagePath='crop.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# image = cv2.imread('crop.jpg')\n",
    "# gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "# binary = cv2.medianBlur(binary, 5)\n",
    "# cv2.imwrite('binary.jpg', binary)\n",
    "from recog import Recog\n",
    "recog = Recog()\n",
    "recog.preprocess('crop.jpg', 'binary.jpg')\n",
    "recog.read('binary.jpg')\n",
    "print(recog.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "reader = easyocr.Reader(['en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'binary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/personal/TaxtDetection/train.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/personal/TaxtDetection/train.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m result \u001b[39m=\u001b[39m reader\u001b[39m.\u001b[39mreadtext(binary)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/personal/TaxtDetection/train.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(result)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'binary' is not defined"
     ]
    }
   ],
   "source": [
    "result = reader.readtext(binary)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from doctr.models import ocr_predictor\n",
    "# from doctr.io import DocumentFile\n",
    "# model = ocr_predictor('db_resnet50', 'crnn_mobilenet_v3_small', pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cropedImgPath = './crop.jpg'\n",
    "# image = DocumentFile.from_images(cropedImgPath)\n",
    "# out = model(image)\n",
    "# print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytesseract\n",
    "# from PIL import Image\n",
    "# print(pytesseract.image_to_string(Image.open(cropedImgPath)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
