{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "# model = YOLO(\"yolov8n.yaml\")  # build a new model from scratch\n",
    "model = YOLO('/home/personal/TaxtDetection/runs/detect/train15/weights/best.pt')  # load a .pt file\n",
    "\n",
    "# Use the model\n",
    "# model.train(data=\"config.yml\", epochs=50, resume=True)  # train the model\n",
    "# metrics = model.val()  # evaluate model performance on the validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/personal/TaxtDetection/data/test/images/00047.jpg: 384x640 1 Tag, 98.5ms\n",
      "Speed: 2.3ms preprocess, 98.5ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from detect import Coords\n",
    "from PIL import Image\n",
    "imgPath = ('./data/test/images/00047.jpg')\n",
    "\n",
    "results = model(imgPath)\n",
    "coords: list[Coords] = list()\n",
    "for result in results:\n",
    "    # print(result.boxes)\n",
    "    for box in result.boxes:\n",
    "        for xyxy in box.xyxy:\n",
    "            coord = Coords(xyxy[0], xyxy[1], xyxy[2], xyxy[3])\n",
    "            coords.append(coord)\n",
    "    # im_array = result.plot()  # plot a BGR numpy array of predictions\n",
    "    # im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
    "    # # im.show()  # show image\n",
    "    # im.save('results.jpg') \n",
    "# print(result[\"boxes\"])\n",
    "# import cv2\n",
    "# print(metrics)\n",
    "# path = model.export(format=\"onnx\") # export the model to ONNX format\n",
    "# print(path)\n",
    "# results = model(img)  # predict on an image\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coord in coords:\n",
    "    coord.drawBoundingBox(imgPath, saveImagePath='draw.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coord in coords:\n",
    "    # Crop image \n",
    "    coord.cropImage(imgPath, saveImagePath='crop.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://doctr-static.mindee.com/models?id=v0.3.1/crnn_mobilenet_v3_small_pt-3b919a02.pt&src=0 to /home/jinyee/.cache/doctr/models/crnn_mobilenet_v3_small_pt-3b919a02.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8421376it [00:02, 3662582.22it/s]                             \n"
     ]
    }
   ],
   "source": [
    "from doctr.models import ocr_predictor\n",
    "from doctr.io import DocumentFile\n",
    "model = ocr_predictor('db_resnet50', 'crnn_mobilenet_v3_small', pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DocumentFile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/personal/TaxtDetection/train.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/personal/TaxtDetection/train.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m cropedImgPath \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./crop.jpg\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/personal/TaxtDetection/train.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m image \u001b[39m=\u001b[39m DocumentFile\u001b[39m.\u001b[39mfrom_images(cropedImgPath)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/personal/TaxtDetection/train.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m out \u001b[39m=\u001b[39m model(image)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/personal/TaxtDetection/train.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(out)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DocumentFile' is not defined"
     ]
    }
   ],
   "source": [
    "cropedImgPath = './crop.jpg'\n",
    "image = DocumentFile.from_images(cropedImgPath)\n",
    "out = model(image)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\f\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "print(pytesseract.image_to_string(Image.open(cropedImgPath)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/personal/TaxtDetection/venv/lib/python3.11/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11060). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "reader = easyocr.Reader(['en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([[125.31671842700025, 60.65835921350013], [395.9492493651437, 34.45052008025839], [397.68328157299976, 58.34164078649987], [127.05075063485626, 84.54947991974161]], 'V-05-{0?10190 |', 0.15974265285507555)]\n"
     ]
    }
   ],
   "source": [
    "result = reader.readtext('crop.jpg')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
